{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\n# 1: SETUP, CONFIGURATION & LIBRARY IMPORTS","metadata":{}},{"cell_type":"code","source":"# Installs the latest development versions of key libraries to ensure compatibility.\n#\n\n# --- 1. Install Libraries from the latest source to ensure compatibility ---\nprint(\"▶ Installing/updating required libraries from the latest sources...\")\n!pip install -q pandas numpy torch yfinance newsapi-python praw\n!pip install -q --upgrade bitsandbytes\n!pip install -q --upgrade git+https://github.com/huggingface/transformers.git\n!pip install -q --upgrade git+https://github.com/huggingface/accelerate.git\n\n# --- 2. Library Imports ---\nimport yfinance as yf\nimport pandas as pd\nimport praw\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom newsapi import NewsApiClient\nfrom datetime import datetime, timedelta\nfrom kaggle_secrets import UserSecretsClient\nimport torch\n\n# --- 3. Main Configuration ---\nTICKER_SYMBOL = 'NVDA'\nSEARCH_KEYWORD = 'NVIDIA'\nSUBREDDITS_TO_SEARCH = ['wallstreetbets', 'investing', 'stocks', 'technology', 'techstocks']\nPOST_LIMIT_PER_SUBREDDIT = 25\nCOMMENT_LIMIT_PER_POST = 10\n\nprint(\"✔ Cell 1/4: All libraries installed and configuration complete. Please restart the session and run all cells.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T17:49:29.730169Z","iopub.execute_input":"2025-08-29T17:49:29.730330Z","iopub.status.idle":"2025-08-29T17:52:02.665850Z","shell.execute_reply.started":"2025-08-29T17:49:29.730315Z","shell.execute_reply":"2025-08-29T17:52:02.665117Z"}},"outputs":[{"name":"stdout","text":"▶ Installing/updating required libraries from the latest sources...\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"},{"name":"stderr","text":"2025-08-29 17:51:48.814231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756489909.007679      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756489909.064763      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"✔ Cell 1/4: All libraries installed and configuration complete. Please restart the session and run all cells.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"---\n# 2. DATA GATHERING AGENT FUNCTIONS","metadata":{}},{"cell_type":"code","source":"# This cell contains all functions responsible for fetching data from external APIs.\n#\n\ndef get_api_credentials():\n    \"\"\"Retrieves all necessary API credentials from Kaggle Secrets.\"\"\"\n    print(\"▶ Attempting to load API credentials from Kaggle Secrets...\")\n    credentials = {}\n    try:\n        user_secrets = UserSecretsClient()\n        credentials['news_api_key'] = user_secrets.get_secret(\"NEWS_API_KEY\")\n        credentials['reddit_client_id'] = user_secrets.get_secret(\"REDDIT_CLIENT_ID\")\n        credentials['reddit_client_secret'] = user_secrets.get_secret(\"REDDIT_CLIENT_SECRET\")\n        credentials['reddit_user_agent'] = f'FinSentimentTracker v0.2 by {user_secrets.get_secret(\"KAGGLE_USERNAME\")}'\n        print(\"✔ All API credentials loaded successfully.\")\n        return credentials\n    except Exception as e:\n        print(f\"ERROR: Could not retrieve one or more API keys. Please check your Kaggle Secrets.\")\n        return None\n\ndef fetch_financial_news(api_key, keyword):\n    \"\"\"Fetches recent financial news using NewsAPI.\"\"\"\n    print(f\"\\\\nFetching news articles for '{keyword}'...\")\n    try:\n        newsapi = NewsApiClient(api_key=api_key)\n        seven_days_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n        all_articles = newsapi.get_everything(q=keyword, language='en', from_param=seven_days_ago, sort_by='relevancy', page_size=100)\n        articles_df = pd.DataFrame(all_articles['articles'])\n        articles_df['source'] = articles_df['source'].apply(lambda x: x.get('name', 'Unknown Source'))\n        articles_df.rename(columns={'title': 'text_for_display'}, inplace=True)\n        print(f\"✔ {len(articles_df)} news articles fetched successfully.\")\n        return articles_df[['source', 'content']]\n    except Exception as e:\n        print(f\"ERROR: Could not fetch news. Details: {e}\")\n        return pd.DataFrame() # Return empty DataFrame on error\n\ndef fetch_reddit_discussions_advanced(creds, keyword, subreddits, post_limit, comment_limit):\n    \"\"\"Fetches top posts AND their top comments from specified subreddits.\"\"\"\n    print(f\"\\\\nFetching Reddit posts and comments for '{keyword}'...\")\n    try:\n        reddit = praw.Reddit(client_id=creds['reddit_client_id'],\n                             client_secret=creds['reddit_client_secret'],\n                             user_agent=creds['reddit_user_agent'])\n        all_texts = []\n        for subreddit_name in subreddits:\n            subreddit = reddit.subreddit(subreddit_name)\n            submissions = subreddit.search(keyword, sort='top', time_filter='week', limit=post_limit)\n            for submission in submissions:\n                all_texts.append({'source': f'Reddit Post (r/{subreddit_name})', 'content': submission.title})\n                if submission.selftext:\n                    all_texts.append({'source': f'Reddit Post (r/{subreddit_name})', 'content': submission.selftext})\n                submission.comments.replace_more(limit=0)\n                for i, comment in enumerate(submission.comments.list()):\n                    if i >= comment_limit: break\n                    all_texts.append({'source': f'Reddit Comment (r/{subreddit_name})', 'content': comment.body})\n        reddit_df = pd.DataFrame(all_texts)\n        print(f\"✔ {len(reddit_df)} total texts fetched from Reddit.\")\n        return reddit_df\n    except Exception as e:\n        print(f\"ERROR: Failed to fetch from Reddit. Details: {e}\")\n        return pd.DataFrame() # Return empty DataFrame on error\n        \nprint(\"✔ Cell 2/4: Data gathering functions are defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T17:52:26.333825Z","iopub.execute_input":"2025-08-29T17:52:26.334420Z","iopub.status.idle":"2025-08-29T17:52:26.345530Z","shell.execute_reply.started":"2025-08-29T17:52:26.334388Z","shell.execute_reply":"2025-08-29T17:52:26.344645Z"}},"outputs":[{"name":"stdout","text":"✔ Cell 2/4: Data gathering functions are defined.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"---\n# 3. SENTIMENT ANALYSIS AND SUMMARIZATION FUNCTIONS","metadata":{}},{"cell_type":"code","source":"# This cell defines the functions for running the FinBERT model and synthesizing the results.\n#\n\ndef analyze_sentiment(data_dataframe):\n    \"\"\"Analyzes the sentiment of a dataframe with a 'content' column.\"\"\"\n    if data_dataframe is None or data_dataframe.empty:\n        print(\"INFO: DataFrame is empty. Skipping sentiment analysis.\")\n        return None\n    print(\"\\\\n▶ Initializing FinBERT sentiment analysis pipeline...\")\n    sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\", device=0 if torch.cuda.is_available() else -1)\n    print(\"✔ FinBERT pipeline ready.\")\n    texts_to_analyze = data_dataframe['content'].fillna('').tolist()\n    if not any(texts_to_analyze):\n        print(\"WARNING: No text content found to analyze.\")\n        return data_dataframe\n    print(f\"▶ Analyzing sentiment for {len(texts_to_analyze)} texts...\")\n    sentiment_results = sentiment_pipeline(texts_to_analyze, truncation=True, batch_size=16)\n    data_dataframe[['sentiment_label', 'sentiment_score']] = pd.DataFrame(sentiment_results)\n    print(\"✔ Sentiment analysis complete.\")\n    return data_dataframe\n\ndef summarize_sentiment_data(analyzed_df, keyword):\n    \"\"\"Calculates key metrics and formats them into a text summary for the LLM.\"\"\"\n    if analyzed_df is None or 'sentiment_label' not in analyzed_df.columns:\n        print(\"ERROR: Sentiment analysis data missing.\")\n        return None\n    print(\"\\\\n▶ Synthesizing sentiment data into a final report...\")\n    sentiment_distribution = analyzed_df['sentiment_label'].value_counts(normalize=True).mul(100)\n    summary = {\n        'positive': sentiment_distribution.get('positive', 0),\n        'negative': sentiment_distribution.get('negative', 0),\n        'neutral': sentiment_distribution.get('neutral', 0),\n        'dominant': sentiment_distribution.idxmax(),\n        'avg_score': analyzed_df['sentiment_score'].mean()\n    }\n    pos_examples = analyzed_df[analyzed_df['sentiment_label'] == 'positive']\n    neg_examples = analyzed_df[analyzed_df['sentiment_label'] == 'negative']\n    summary['top_positive'] = pos_examples.loc[pos_examples['sentiment_score'].idxmax()]['content'][:150] if not pos_examples.empty else \"N/A\"\n    summary['top_negative'] = neg_examples.loc[neg_examples['sentiment_score'].idxmax()]['content'][:150] if not neg_examples.empty else \"N/A\"\n    \n    summary_text = f\"\"\"\n### Financial Sentiment Analysis Report: {keyword} ###\n**1. Overall Sentiment Distribution:**\n- Positive: {summary['positive']:.2f}%\n- Negative: {summary['negative']:.2f}%\n- Neutral: {summary['neutral']:.2f}%\n**2. Key Insights:**\n- The dominant sentiment in recent online discussions is **{summary['dominant']}**.\n- The average model confidence score was **{summary['avg_score']:.4f}**.\n**3. Representative Snippets:**\n- **Example of Positive Sentiment:** \"{summary['top_positive']}...\"\n- **Example of Negative Sentiment:** \"{summary['top_negative']}...\"\nThis summary is based on {len(analyzed_df)} texts from news and Reddit.\n\"\"\"\n    print(\"✔ Data-driven summary for the LLM has been generated.\")\n    return summary_text\n\nprint(\"✔ Cell 3/4: Analysis and summarization functions are defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T17:52:29.883147Z","iopub.execute_input":"2025-08-29T17:52:29.883399Z","iopub.status.idle":"2025-08-29T17:52:29.892382Z","shell.execute_reply.started":"2025-08-29T17:52:29.883380Z","shell.execute_reply":"2025-08-29T17:52:29.891649Z"}},"outputs":[{"name":"stdout","text":"✔ Cell 3/4: Analysis and summarization functions are defined.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"---\n# 4. MAIN EXECUTION PIPELINE","metadata":{}},{"cell_type":"code","source":"# This cell runs the entire data gathering, analysis, and summarization process.\n#\n\nif __name__ == '__main__':\n    api_credentials = get_api_credentials()\n    \n    # Initialize an empty DataFrame to hold all content\n    all_content_df = pd.DataFrame()\n\n    if api_credentials:\n        # Step 1: Gather data from all sources\n        news_df = fetch_financial_news(api_credentials['news_api_key'], SEARCH_KEYWORD)\n        reddit_df = fetch_reddit_discussions_advanced(api_credentials, SEARCH_KEYWORD, SUBREDDITS_TO_SEARCH, POST_LIMIT_PER_SUBREDDIT, COMMENT_LIMIT_PER_POST)\n        \n        # Combine the dataframes\n        all_content_df = pd.concat([news_df, reddit_df], ignore_index=True)\n            \n    if not all_content_df.empty:\n        print(f\"\\\\n--- Total of {len(all_content_df)} texts gathered for analysis ---\")\n        \n        # Step 2: Analyze the combined data\n        analyzed_df = analyze_sentiment(all_content_df)\n        \n        if analyzed_df is not None:\n            # Step 3: Summarize the results\n            llm_briefing = summarize_sentiment_data(analyzed_df, SEARCH_KEYWORD)\n            if llm_briefing:\n                print(\"\\\\n\" + \"=\"*25 + \" FINAL BRIEFING FOR LLM \" + \"=\"*25)\n                print(llm_briefing)\n                print(\"=\"*75)\n    else:\n        print(\"\\\\nExecution halted: No data could be fetched from any source.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T17:52:32.483133Z","iopub.execute_input":"2025-08-29T17:52:32.483973Z","iopub.status.idle":"2025-08-29T17:53:12.383958Z","shell.execute_reply.started":"2025-08-29T17:52:32.483940Z","shell.execute_reply":"2025-08-29T17:53:12.383124Z"}},"outputs":[{"name":"stdout","text":"▶ Attempting to load API credentials from Kaggle Secrets...\n✔ All API credentials loaded successfully.\n\\nFetching news articles for 'NVIDIA'...\n✔ 100 news articles fetched successfully.\n\\nFetching Reddit posts and comments for 'NVIDIA'...\n✔ 480 total texts fetched from Reddit.\n\\n--- Total of 580 texts gathered for analysis ---\n\\n▶ Initializing FinBERT sentiment analysis pipeline...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6db249205c541b985d08cffb06ad1a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d1af3ef70aa45ceb1bde8e337f60dd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed25c6c2fa8b4d7f8841e72149065010"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f98b8a38608f42c3a22665a5fe480c4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7fc42a6cd954cd5a71da06acf4acb11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd48df3afc384b4fa8806199bb1fa7aa"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"✔ FinBERT pipeline ready.\n▶ Analyzing sentiment for 580 texts...\n✔ Sentiment analysis complete.\n\\n▶ Synthesizing sentiment data into a final report...\n✔ Data-driven summary for the LLM has been generated.\n\\n========================= FINAL BRIEFING FOR LLM =========================\n\n### Financial Sentiment Analysis Report: NVIDIA ###\n**1. Overall Sentiment Distribution:**\n- Positive: 10.52%\n- Negative: 12.76%\n- Neutral: 76.72%\n**2. Key Insights:**\n- The dominant sentiment in recent online discussions is **neutral**.\n- The average model confidence score was **0.8114**.\n**3. Representative Snippets:**\n- **Example of Positive Sentiment:** \"NVIDIA Corporation (NASDAQ:NVDA) is among the best stocks to buy now according to AI. J.W. Cole Advisors Inc. has increased its stake in NVIDIA Corpor...\"\n- **Example of Negative Sentiment:** \"MRVL also down -12% via earnings in afterhours...\"\nThis summary is based on 580 texts from news and Reddit.\n\n===========================================================================\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"---\n# 4. FIXING: \"ImportError: Using bitsandbytes 4-bit quantization requires the latest version of bitsandbytes: pip install -U bitsandbytes\"","metadata":{}},{"cell_type":"code","source":"%pip show bitsandbytes\n%pip install -U bitsandbytes\n%pip show bitsandbytes\n%pip show transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T17:55:30.743868Z","iopub.execute_input":"2025-08-29T17:55:30.744569Z","iopub.status.idle":"2025-08-29T17:55:39.801697Z","shell.execute_reply.started":"2025-08-29T17:55:30.744545Z","shell.execute_reply":"2025-08-29T17:55:39.800834Z"}},"outputs":[{"name":"stdout","text":"Name: bitsandbytes\nVersion: 0.47.0\nSummary: k-bit optimizers and matrix multiplication routines.\nHome-page: https://github.com/bitsandbytes-foundation/bitsandbytes\nAuthor: \nAuthor-email: Tim Dettmers <dettmers@cs.washington.edu>\nLicense: MIT License\n\nCopyright (c) Facebook, Inc. and its affiliates.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: numpy, torch\nRequired-by: \nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.47.0)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nName: bitsandbytes\nVersion: 0.47.0\nSummary: k-bit optimizers and matrix multiplication routines.\nHome-page: https://github.com/bitsandbytes-foundation/bitsandbytes\nAuthor: \nAuthor-email: Tim Dettmers <dettmers@cs.washington.edu>\nLicense: MIT License\n\nCopyright (c) Facebook, Inc. and its affiliates.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: numpy, torch\nRequired-by: \nNote: you may need to restart the kernel to use updated packages.\nName: transformers\nVersion: 4.56.0.dev0\nSummary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\nHome-page: https://github.com/huggingface/transformers\nAuthor: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\nAuthor-email: transformers@huggingface.co\nLicense: Apache 2.0 License\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\nRequired-by: kaggle-environments, peft, sentence-transformers\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"---\n# 5. LLM CRITIQUE GENERATION (with Professional Persona)","metadata":{}},{"cell_type":"code","source":"# This script loads Meta-Llama 3, feeds it the synthesized data,\n# and generates a human-readable financial critique using a detailed persona.\n#\n\n!pip install --upgrade transformers accelerate bitsandbytes\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport torch\nfrom kaggle_secrets import UserSecretsClient\n\n# This is the summary text generated from the previous cell.\n# For the code to run, this variable must contain that summary string.\nllm_briefing = \"\"\"\n### Financial Sentiment Analysis Report: NVIDIA ###\n**1. Overall Sentiment Distribution:**\n- Positive: 10.23%\n- Negative: 12.70%\n- Neutral: 77.07%\n**2. Key Insights:**\n- The dominant sentiment in recent online discussions is **neutral**.\n- The average model confidence score was **0.8113**.\n**3. Representative Snippets:**\n- **Example of Positive Sentiment:** \"NVIDIA Corporation (NASDAQ:NVDA) is among the best stocks to buy now according to AI. J.W. Cole Advisors Inc. has increased its stake in NVIDIA Corpor...\"\n- **Example of Negative Sentiment:** \"MRVL also down -12% via earnings in afterhours...\"\nThis summary is based on 567 texts from news and Reddit.\n\"\"\"\n\n# --- 2. AGENT 3: THE SCRIBE (Llama 3) ---\n\ndef load_llm(model_id=\"meta-llama/Meta-Llama-3-8B-Instruct\"):\n    \"\"\"\n    Loads the specified Large Language Model with 4-bit quantization.\n    \"\"\"\n    print(f\"\\\\n▶ Loading the Large Language Model: {model_id}...\")\n    print(\"This may take a few minutes...\")\n    \n    try:\n        user_secrets = UserSecretsClient()\n        hf_token = user_secrets.get_secret(\"HUGGING_FACE_HUB_TOKEN\")\n    except:\n        print(\"WARNING: 'HUGGING_FACE_HUB_TOKEN' not found. Model download may fail.\")\n        hf_token = None\n\n    quantization_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.bfloat16\n    )\n\n    tokenizer = AutoTokenizer.from_pretrained(model_id, token=hf_token)\n    model = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        token=hf_token,\n        quantization_config=quantization_config,\n        device_map=\"auto\",\n    )\n    \n    print(\"✔ LLM loaded successfully!\")\n    return model, tokenizer\n\ndef generate_critique(model, tokenizer, summary_report):\n    \"\"\"\n    Generates a financial critique using the LLM based on the provided summary.\n    \"\"\"\n    print(\"▶ Preparing prompt for the Scribe Agent (Llama 3)...\")\n    \n    # UPDATED: Using the user's advanced system prompt for a professional persona\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a senior financial analyst with 15+ years of experience in equity research and market sentiment analysis at a top-tier investment firm. Your task is to produce a concise, data-driven, and strictly objective analysis of a company's recent public sentiment based exclusively on the quantitative metrics and qualitative examples provided. Adhere to the following structured format and guidelines:\\n\\n**Analysis Structure:**\\n1. **Executive Headline** (10-15 words): Craft a precise, actionable headline that captures the sentiment trend and its potential market impact.\\n2. **Quantitative Overview** (100-150 words): Interpret the sentiment distribution with specific attention to the exact percentage breakdowns.\\n3. **Qualitative Deep-Dive** (100-150 words): Analyze the specific examples provided, focusing on key themes in positive and negative sentiment.\\n\\n**Critical Constraints:**\\n- Base all statements solely on the provided data—no external information or speculation.\\n- Maintain strict neutrality—avoid promotional or alarmist language.\\n- Use precise financial terminology.\",\n        },\n        {\"role\": \"user\", \"content\": summary_report},\n    ]\n\n    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n\n    print(\"▶ Generating final critique...\")\n    \n    outputs = model.generate(**inputs, max_new_tokens=768, do_sample=True, temperature=0.6, top_p=0.9, eos_token_id=tokenizer.eos_token_id)\n    response_text = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n    \n    return response_text\n\n# --- 3. EXECUTION ---\nif __name__ == '__main__':\n    if 'llm_briefing' in locals() and llm_briefing:\n        # Load the LLM and tokenizer\n        llm_model, llm_tokenizer = load_llm()\n        \n        # Generate the final report using the new persona\n        final_report = generate_critique(llm_model, llm_tokenizer, llm_briefing)\n        \n        print(\"\\\\n\" + \"=\"*25 + \" FINAL AI-GENERATED REPORT \" + \"=\"*25)\n        print(final_report)\n        print(\"=\"*75)\n    else:\n        # This is a fallback in case the briefing wasn't generated\n        print(\"ERROR: 'llm_briefing' variable not\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T17:56:06.373096Z","iopub.execute_input":"2025-08-29T17:56:06.373736Z","iopub.status.idle":"2025-08-29T17:59:44.391912Z","shell.execute_reply.started":"2025-08-29T17:56:06.373706Z","shell.execute_reply":"2025-08-29T17:59:44.391099Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.56.0.dev0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.11.0.dev0)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n\\n▶ Loading the Large Language Model: meta-llama/Meta-Llama-3-8B-Instruct...\nThis may take a few minutes...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"318b34c3fb444962b01a942a1806f9eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6432f52c1f5e4c18b89ec33e5e3f4e11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dff06a95dcc146158a2c5ce0a12cfc94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"244392fef6314689a189548af21bfb4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f21810b2efe4ea7860d5b115b4cf5c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"448fbca12de4425c8fb878c411ce2257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"718bc49b6be047cbaa913d6bbbf657f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"720862c9d3714f66913de5819e8bb749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9012016e0d374e518515b236b48b4e10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4970bdd4991f4921a86c199493e35f67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed9b897a610d4fb38741e51893673265"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d392eda979844ca793ac749eab7ee673"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"✔ LLM loaded successfully!\n▶ Preparing prompt for the Scribe Agent (Llama 3)...\n▶ Generating final critique...\n\\n========================= FINAL AI-GENERATED REPORT =========================\n**Executive Headline:** NVIDIA's Neutral Sentiment Dominates Online Discussions, Amidst Mixed Market Reaction\n\n**Quantitative Overview:** The recent sentiment analysis of NVIDIA Corporation (NASDAQ:NVDA) reveals a predominantly neutral sentiment distribution, with 77.07% of online discussions falling under this category. The remaining 10.23% and 12.70% are comprised of positive and negative sentiments, respectively. The average model confidence score of 0.8113 suggests a moderate level of accuracy in the sentiment analysis.\n\n**Qualitative Deep-Dive:** The neutral sentiment is largely driven by the mixed market reaction to NVIDIA's recent performance. The positive sentiment, exemplified by the statement \"NVIDIA Corporation (NASDAQ:NVDA) is among the best stocks to buy now according to AI,\" highlights the company's strong fundamentals and growth prospects. However, the negative sentiment, as seen in the statement \"MRVL also down -12% via earnings in afterhours,\" reflects the market's concerns about the company's earnings and potential future performance. Overall, the neutral sentiment indicates that investors are taking a wait-and-see approach, awaiting further developments before making a move.\n===========================================================================\n","output_type":"stream"}],"execution_count":6}]}